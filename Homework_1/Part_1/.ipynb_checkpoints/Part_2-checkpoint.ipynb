{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4e7b4e-cf3e-4f50-82fa-fce3c4760492",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3564b642-1ae7-4f16-a8e1-0291367e99d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72edcd8-4d5b-4bd9-a741-4519f58ceb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "Part 2 : Part 2: 2D Object Recognition using CNNs"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9bc768a0-430f-4797-9c53-4270d3b02f34",
   "metadata": {},
   "source": [
    "** You are provided with a Python library that can generate objects with various shapes and sizes. This code is given in:\n",
    "https://github.com/TimoFlesch/2D-Shape-Generator\n",
    "You are asked to use the images generated by this function to train a CNN that recognizes the shape of the object in each image. You are asked to generate various images of the following shape classes:\n",
    "\n",
    "Oval: Oval shaped (of varying shape, size, orientation, and location in the image).\n",
    "Rectangle: Rectangular shaped (of varying shape, size, orientation, and location in the image).\n",
    "Triangle: Triangular shaped (of varying shape, size, orientation, and location in the image).\n",
    "Ploy 5: Polygonal shapes with 5 sides (of varying shape, size, orientation, and location ..).\n",
    "Poly 6: Polygonal shapes with 6 sides (of varying shape, size, orientation, and location …).\n",
    "Poly 7: Polygonal shaped with 7 sides (of varying shape, size, orientation, and location …).\n",
    "Star 5: A five vertex star (of varying shape, size, orientation, and location …).\n",
    "Star 8: An eight-vertex star (of varying shape, size, orientation, and location…).\n",
    "\n",
    "You are expected to do the following:\n",
    "1.Generate your data (online or offline) with 128x128 pixel images. Your data should have salt and pepper noise added in the images. Use only black-and-white colors.\n",
    "\n",
    "2.Start with the AlexNet model. Change the input layer to handle grayscale images. Change the number of outputs to the right number of object classes.\n",
    "3.Train the network with the data and report results.\n",
    "a.Use at least two different learning rate adjustment schemes.\n",
    "b.Use at least three different activation functions.\n",
    "\n",
    "4.Change the network architecture.\n",
    "a.Change the number of nodes in the fully connected layer by 10% for three times and repeat Step 3.\n",
    "b.Continuing with %15 of the nodes in the fully connected layer, remove the third layer from the output and repeat Step 3.\n",
    "c.Continuing with %20 of the nodes in the fully connected layer, remove the third and fourth layers from the output and repeat Step 3."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
