{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "445c9594-0533-44bf-8cee-a61b578e8967",
   "metadata": {},
   "source": [
    "# CSE555 – Deep Learning (Fall 2023)\n",
    "# Homework_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3564b642-1ae7-4f16-a8e1-0291367e99d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86f862dc-2c53-45d6-bee6-5245462ff4ae",
   "metadata": {},
   "source": [
    "## Part 2 : 2D Object Recognition using CNNs"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9bc768a0-430f-4797-9c53-4270d3b02f34",
   "metadata": {},
   "source": [
    "** You are provided with a Python library that can generate objects with various shapes and sizes. This code is given in:\n",
    "https://github.com/TimoFlesch/2D-Shape-Generator\n",
    "You are asked to use the images generated by this function to train a CNN that recognizes the shape of the object in each image. You are asked to generate various images of the following shape classes:\n",
    "\n",
    "Oval: Oval shaped (of varying shape, size, orientation, and location in the image).\n",
    "Rectangle: Rectangular shaped (of varying shape, size, orientation, and location in the image).\n",
    "Triangle: Triangular shaped (of varying shape, size, orientation, and location in the image).\n",
    "Ploy 5: Polygonal shapes with 5 sides (of varying shape, size, orientation, and location ..).\n",
    "Poly 6: Polygonal shapes with 6 sides (of varying shape, size, orientation, and location …).\n",
    "Poly 7: Polygonal shaped with 7 sides (of varying shape, size, orientation, and location …).\n",
    "Star 5: A five vertex star (of varying shape, size, orientation, and location …).\n",
    "Star 8: An eight-vertex star (of varying shape, size, orientation, and location…).\n",
    "\n",
    "You are expected to do the following:\n",
    "1.Generate your data (online or offline) with 128x128 pixel images. Your data should have salt and pepper noise added in the images. Use only black-and-white colors.\n",
    "\n",
    "2.Start with the AlexNet model. Change the input layer to handle grayscale images. Change the number of outputs to the right number of object classes.\n",
    "3.Train the network with the data and report results.\n",
    "a.Use at least two different learning rate adjustment schemes.\n",
    "b.Use at least three different activation functions.\n",
    "\n",
    "4.Change the network architecture.\n",
    "a.Change the number of nodes in the fully connected layer by 10% for three times and repeat Step 3.\n",
    "b.Continuing with %15 of the nodes in the fully connected layer, remove the third layer from the output and repeat Step 3.\n",
    "c.Continuing with %20 of the nodes in the fully connected layer, remove the third and fourth layers from the output and repeat Step 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dae92fd-e273-42f8-a181-0df6731b2888",
   "metadata": {},
   "source": [
    "Data Set :  https://github.com/TimoFlesch/2D-Shape-Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f9c372-7878-412a-8555-cd5dbbbdc696",
   "metadata": {},
   "outputs": [],
   "source": [
    "Requirements:\n",
    "pip install python==3.6.1\n",
    "pip install matplotlib==2.0.2\n",
    "pip install numpy==1.12.1\n",
    "pip install scipy==0.19.0\n",
    "pip install pycairo==1.13.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9f0eaf-358f-41a5-9299-c951550245de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install cairo\n",
    "!pip3 install pycairo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fede6f4-0f64-4106-85de-39f543e52b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75277eac-448c-48ac-9a18-5aae304aab11",
   "metadata": {},
   "source": [
    "# Import libraries & data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b763fc-0d4f-42cf-88e9-4849dd375c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "np.random.seed(123)\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "import keras\n",
    "from keras.utils.np_utils import to_categorical # used for converting labels to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import itertools\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b93d18e-3979-4426-9738-2ab36a11b020",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc74dc2-7821-480b-ba9a-9cd4ffe7d6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve, average_precision_score\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a354a70b-0d3d-45c3-9c52-c5e83cbad86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "function to generate 2D shape stimulus sets, heavily inspired by Higgins et al 2016\n",
    "\n",
    "Each image consists of a geometric shape (polygon, ellipse, star) on a (default: black) background. \n",
    "Individual shape instances can be modulated parametrically in terms of\n",
    "- translation (x,y)\n",
    "- rotation\n",
    "- scale \n",
    "- colour\n",
    "\n",
    "Timo Flesch, 2017\n",
    "\"\"\"\n",
    "import cairo \n",
    "import argparse\n",
    "import numpy as np\n",
    "from paint_studio.painter import drawStimuli\n",
    "from fio.saver            import saveData\n",
    "\n",
    "\n",
    "# PARAMETERS ----------------------------------------------------------------------------\n",
    "parser = argparse.ArgumentParser()\n",
    "# general -------------------------------------------------------------------------------\n",
    "parser.add_argument('--outdir','-o',           type=str,   nargs='+', default='./output/', \n",
    "\t                                           help='Output directory (default: ./output/')\n",
    "parser.add_argument('--name',                  type=str,   nargs='+', default=['stim2D_'],\n",
    "                                               help='File Name (default: stim2D_')\n",
    "parser.add_argument('--parallel',              type=int,   nargs=1,   default=0, \n",
    "\t                                           help='Do Parallel Processing (default: 0)')\n",
    "\n",
    "# canvas --------------------------------------------------------------------------------\n",
    "parser.add_argument('--canvas_size',           type=int,   nargs='+', default=[128, 128], # change   pixel \n",
    "                                               help='Size of Image Canvas (default: 128x128px)') \n",
    "parser.add_argument('--canvas_bgcol',          type=float, nargs='+', default=[0.,0.,0.], \n",
    "\t                                           help='Background Colour of Image Canvas (RGB,default: 0 0 0)')\n",
    "\n",
    "# stimuli -------------------------------------------------------------------------------\n",
    "parser.add_argument('--num_stimuli',           type=int,   nargs=1,   default=1, \n",
    "\t                                           help='Number of stimuli per shape to generate (default: 1)') \n",
    "parser.add_argument('--num_transformations',   type=int,              default=0, \n",
    "\t                                           help='Number of linearly spaced transformations (default:0)')\n",
    "parser.add_argument('--shapes',                type=str,   nargs='+', default=['rect','ellipse', 'oval', 'poly6', 'poly7', 'star5', 'star8'], # those  all shape names  data set\n",
    "\t                                           help='Shapes (rect, polyNUM,starNUM, ellipse) ')\n",
    "parser.add_argument('--to_transform',          type=str,   nargs='+', default=[],\n",
    "\t                                           help='dimensions to transform with num_transformations. \\\n",
    "\t                                           All other dims kept constant (scale,rota,trx,try,colour; default: None)')\n",
    "parser.add_argument('--stim_poly_size',        type=int,                default=20,\n",
    "\t                                           help='Polygon \"Radius\"  (default: 50)')\n",
    "parser.add_argument('--stim_star_size',        type=float,   nargs='+', default=[20,10],\n",
    "\t                                           help='Star Radii (outer, inner; default: [50,25])')\n",
    "parser.add_argument('--stim_ellipse_ratio',    type=float, nargs='+', default=[1,.5],\n",
    "\t                                           help='Scaling of Circle to generate Ellipse')\n",
    "parser.add_argument('--stim_rect_ratio',    type=float, nargs='+', default=[.5,1],\n",
    "\t                                           help='Scaling of square to generate rect')\n",
    "parser.add_argument('--stim_scale',            type=float, nargs='+', default=[1,1],\n",
    "\t                                           help='Stimulus Scaling (default: (1,1)')\n",
    "parser.add_argument('--stim_rota',             type=float,            default=0,\n",
    "                                               help='Stimulus Rotation (deg; default: 0)')\n",
    "parser.add_argument('--stim_trx',              type=float,             default=125,\n",
    "\t                                           help='Stimulus Translation along x (default: centre)')\n",
    "parser.add_argument('--stim_try',              type=float,             default=125,\n",
    "\t                                           help='Stimulus Translation along y (default: 0)')\n",
    "parser.add_argument('--stim_colour',           type=float,  nargs='+', default=[1., 1., 1.],\n",
    "\t                                           help='Stimulus Colour (default: [1.,1.,1.]')\n",
    "\n",
    "# transformation ranges -----------------------------------------------------------------\n",
    "parser.add_argument('--rng_ratio',             type=float, nargs='+', default=[.2, 5.],\n",
    "                                               help='Shape width to height ratio (min,max; defaults:[.2, 5.]')\n",
    "parser.add_argument('--rng_trx',               type=float, nargs='+', default=[.10, .90],\n",
    "                                               help='Translation along x in decimal fractions (min,max; defaults:[.05, .95]')\n",
    "parser.add_argument('--rng_try',               type=float, nargs='+', default=[.10, .90], \n",
    "\t                                           help='Translation along y in decimal fractions (min,max; defaults:[.05, .95]')\n",
    "parser.add_argument('--rng_rota',              type=int,   nargs='+', default=[-45, 45], \n",
    "\t                                           help='Rotation in deg (min,max; defaults:[-45, 45]')\n",
    "parser.add_argument('--rng_scale',             type=float, nargs='+', default=[.5, 1.5],\n",
    "                                               help='Scale decimal fractions (min,max; defaults:[.2, 1.]')\n",
    "\n",
    "\n",
    "FLAGS,_ = parser.parse_known_args() # ignore unspecified args\n",
    "FLAGS.rng_trx = np.multiply(FLAGS.rng_trx,FLAGS.canvas_size)\n",
    "FLAGS.rng_try = np.multiply(FLAGS.rng_try,FLAGS.canvas_size)\n",
    "print(FLAGS)\n",
    "\n",
    "def main(argv=None):\t\n",
    "\tall_IMGs,all_idces = drawStimuli(FLAGS)\n",
    "\tdata = {}\n",
    "\tdata['images'] = all_IMGs # store all the images\n",
    "\tdata['params'] = vars(FLAGS) # store all the parameters\n",
    "\tdata['idces']  = all_idces  # for each image, store the feature values. (feature correspondence encoded in FLAGS.to_transform (same order))\n",
    "\tsaveData(data,FLAGS.to_transform,FLAGS.shapes,FLAGS.outdir)\n",
    "if __name__ == '__main__':\n",
    "\t\"\"\" start the fun\"\"\"\n",
    "\tmain()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c25a30-ea59-45ce-aba1-4ad6f2439a99",
   "metadata": {},
   "source": [
    "# this code was executed but could not generate the required images. Therefore only the model was installed.  If I could generate images I could try it on the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270b52d8-99bd-4364-8fff-086ba82febb1",
   "metadata": {},
   "source": [
    "# Loading Images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdf16b0-4ed7-4d5a-a82d-e8359c2dd2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Image paths\n",
    "image_paths = [\"path/to/image1.jpg\", \"path/to/image2.jpg\", ...]\n",
    "\n",
    "# Function to load and preprocess images\n",
    "def load_and_preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, (224, 224, 1))\n",
    "    image = image / 255.0  # Scaling pixel values to [0, 1]\n",
    "    return image\n",
    "\n",
    "# Load all images in an array\n",
    "images = [load_and_preprocess_image(image_path) for image_path in image_paths]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a92f02-e376-423e-abdb-bbe829faa389",
   "metadata": {},
   "source": [
    "# Creating Labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0d7a2b-4bd4-439a-8c59-7c590d786bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example, match each shape  image to a class number\n",
    "labels = [0, 1, 2, 3, 4, 5, 6, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ae82d6-0138-48a0-9c00-7172cd5e7043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert images to a NumPy array\n",
    "X = np.array(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2440e7c8-76b1-4e3a-bd75-545e461a954c",
   "metadata": {},
   "source": [
    "# Splitting into Training and Test Sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20616ba7-41c2-4526-a5f0-267c57e1d598",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb69b6d4-b2ef-412f-800b-565b6fa789ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26be7f77-f3a3-4c5b-aeb9-863ba7dde653",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# AlexNet architecture\n",
    "model.add(layers.Conv2D(96, (11, 11), strides=(4, 4), activation='relu', input_shape=(224, 224, 1)))\n",
    "model.add(layers.MaxPooling2D((3, 3), strides=(2, 2)))\n",
    "model.add(layers.Conv2D(256, (5, 5), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((3, 3), strides=(2, 2)))\n",
    "model.add(layers.Conv2D(384, (3, 3), activation='relu'))\n",
    "model.add(layers.Conv2D(384, (3, 3), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((3, 3), strides=(2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(4096, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(4096, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(8, activation='softmax'))  # Class number 8\n",
    "\n",
    "# Model compile\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7aa479-4480-4b35-8277-92e5323bfe32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c4bbc6-a42a-4be9-8ec2-ca707b78cb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0906d1be-470c-4e3d-9b8d-5388d916e025",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97b3de6-54ae-4b50-a708-f441a2c4d96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test loss: {test_loss}')\n",
    "print(f'Test accuracy: {test_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a152399-e602-4ebd-996b-e6b71258ec1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a10a61-234d-47e5-9d88-2726ae7a3b31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
